import { Audio } from 'expo-av';
import { useEffect, useRef, useState } from 'react';
import { Alert } from 'react-native';
import AudioRecord from 'react-native-audio-record';
import RNFS from 'react-native-fs';
import { initWhisper, WhisperContext } from 'whisper.rn';

export function useLocalWhisper() {
  const [whisperContext, setWhisperContext] = useState<WhisperContext | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [recordedAudioPath, setRecordedAudioPath] = useState<string | null>(null);
  const [downloadProgress, setDownloadProgress] = useState<number>(0);
  const downloadJobId = useRef<number>(-1);

  // ã€æ–°è¦ã€‘ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã®ãƒ­ã‚°ã‚’ç®¡ç†ã™ã‚‹ã‚¹ãƒ†ãƒ¼ãƒˆ
  const [processLogs, setProcessLogs] = useState<string[]>([]);

  // ãƒ­ã‚°ã‚’è¿½åŠ ã—ã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¨UIã®ä¸¡æ–¹ã«å‡ºåŠ›ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
  const addPhaseLog = (logMessage: string) => {
    console.log(`[Pipeline] ${logMessage}`);
    setProcessLogs(prev => [...prev, logMessage]);
  };

  useEffect(() => {
    async function loadModel() {
      try {
        const documentDirectory = RNFS.DocumentDirectoryPath;
        if (!documentDirectory) throw new Error('ç«¯æœ«ã®ä¿å­˜é ˜åŸŸã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚');
        const finalPath = `${documentDirectory}/ggml-base.bin`;
        const tmpPath = `${documentDirectory}/ggml-base.tmp`;

        if (await RNFS.exists(tmpPath)) await RNFS.unlink(tmpPath);

        let needsDownload = true;
        if (await RNFS.exists(finalPath)) {
          const stat = await RNFS.stat(finalPath);
          if (stat.size / (1024 * 1024) > 100) {
            needsDownload = false;
            setTranscription('AIã®æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã™ã€‚');
          } else {
            await RNFS.unlink(finalPath);
          }
        }

        if (needsDownload) {
          setTranscription('é«˜ç²¾åº¦AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...');
          const modelUrl = 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin';
          const ret = RNFS.downloadFile({
            fromUrl: modelUrl,
            toFile: tmpPath,
            progressInterval: 200,
            progress: (res) => {
              setDownloadProgress(Math.round((res.bytesWritten / res.contentLength) * 100));
            }
          });
          downloadJobId.current = ret.jobId;

          const downloadResult = await ret.promise;
          if (downloadResult.statusCode === 200) {
            await RNFS.moveFile(tmpPath, finalPath);
            setDownloadProgress(0);
            setTranscription('é«˜ç²¾åº¦AIã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚');
          } else {
             throw new Error(`HTTP ${downloadResult.statusCode}`);
          }
        }

        const context = await initWhisper({ filePath: finalPath });
        setWhisperContext(context);
      } catch (error: any) {
        console.error('ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—', error);
        setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šAIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
      }
    }
    loadModel();
  }, []);

  function cancelDownload() {
    if (downloadJobId.current !== -1) {
      RNFS.stopDownload(downloadJobId.current);
      setDownloadProgress(0);
      setTranscription('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚');
    }
  }

  async function startRecording() {
    try {
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        Alert.alert('æ¨©é™ã‚¨ãƒ©ãƒ¼', 'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
        return;
      }
      
      // æ¯å›æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã§éŒ²éŸ³ã™ã‚‹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚„ãƒ˜ãƒƒãƒ€ç ´æã®å›é¿ï¼‰
      const timestamp = new Date().getTime();
      const newWavFile = `whisper_audio_${timestamp}.wav`;
      
      AudioRecord.init({ 
        sampleRate: 16000,
        channels: 1,      
        bitsPerSample: 16,
        audioSource: 1,   
        wavFile: newWavFile 
      });
      
      AudioRecord.start();
      setIsRecording(true);
      setRecordedAudioPath(null);
      setProcessLogs([]); // éŒ²éŸ³é–‹å§‹æ™‚ã«ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢
      setTranscription('éŒ²éŸ³ä¸­...');
    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚');
    }
  }

  async function stopRecording() {
    if (!isRecording) return;
    try {
      const path = await AudioRecord.stop();
      setIsRecording(false);
      
      // ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿å®Œäº†ã‚’å°‘ã—å¾…ã¤ï¼ˆAndroidã®ãƒ˜ãƒƒãƒ€æ›´æ–°é…å»¶å¯¾ç­–ï¼‰
      await new Promise(resolve => setTimeout(resolve, 500));

      const finalPath = path.startsWith('file://') ? path : `file://${path}`;
      setRecordedAudioPath(finalPath);
      setTranscription('éŒ²éŸ³ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã€Œä¿å­˜ã—ã¦æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚');
    } catch (error) {
      console.error('éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼', error);
    }
  }

  // ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ·æ–°ã€‘ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã§ã¯ãªãã€ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã®çŠ¶æ…‹ã‚’ãƒ­ã‚®ãƒ³ã‚°ã™ã‚‹
  async function saveAndTranscribe() {
    if (!recordedAudioPath || !whisperContext || isProcessing) return;
    setIsProcessing(true);
    setProcessLogs([]);
    setTranscription('');

    try {
      addPhaseLog('Phase 1: éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚');
      const cleanPath = recordedAudioPath.replace(/^file:\/\//, '');
      addPhaseLog(`-> å¯¾è±¡ãƒ‘ã‚¹: ${cleanPath}`);

      addPhaseLog('Phase 2: OSãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ä¸Šã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚');
      const exists = await RNFS.exists(cleanPath);
      if (!exists) throw new Error('OSä¸Šã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚');
      
      const stat = await RNFS.stat(cleanPath);
      addPhaseLog(`-> å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ${stat.size} bytes`);
      if (stat.size < 1000) throw new Error('ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ1000 bytesæœªæº€ï¼‰ã€‚');

      addPhaseLog('Phase 3: WAVãƒ˜ãƒƒãƒ€ï¼ˆå…ˆé ­44ãƒã‚¤ãƒˆï¼‰ã®æ•´åˆæ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚');
      // ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­44ãƒã‚¤ãƒˆã‚’Base64æ–‡å­—åˆ—ã¨ã—ã¦æŠ½å‡º
      const headerBase64 = await RNFS.read(cleanPath, 44, 0, 'base64');
      addPhaseLog(`-> ãƒ˜ãƒƒãƒ€(Base64): ${headerBase64.substring(0, 25)}...`);

      addPhaseLog('Phase 4: C++ AIã‚¨ãƒ³ã‚¸ãƒ³ã¸ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ¸¡ã—ã€æ¨è«–ã‚’é–‹å§‹ã—ã¾ã™ã€‚');
      // â€»onProgressã¯UIãƒ•ãƒªãƒ¼ã‚ºã®åŸå› ã¨ãªã‚‹ãŸã‚å¤–ã—ã€å®Œäº†ã®ã¿ã‚’å¾…ã¤
      const { result } = await whisperContext.transcribe(cleanPath, { language: 'ja' });
      
      addPhaseLog('Phase 5: C++ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰å‡¦ç†çµæœãŒè¿”å´ã•ã‚Œã¾ã—ãŸã€‚');
      if (!result || result.trim() === '') {
        addPhaseLog('-> è­¦å‘Š: å‡¦ç†ã¯æ­£å¸¸çµ‚äº†ã—ã¾ã—ãŸãŒã€èªè­˜ã•ã‚ŒãŸæ–‡å­—åˆ—ãŒç©ºã§ã—ãŸã€‚WAVãƒ˜ãƒƒãƒ€ç ´æã®ç–‘ã„ãŒã‚ã‚Šã¾ã™ã€‚');
        setTranscription('ï¼ˆæ¨è«–å®Œäº†ï¼šèªè­˜ã•ã‚ŒãŸè¨€è‘‰ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰');
      } else {
        addPhaseLog(`-> å‡ºåŠ›æˆåŠŸ: ${result}`);
        setTranscription(result);
      }
    } catch (error: any) {
      console.error('æ¨è«–å¤±æ•—', error);
      addPhaseLog(`Phase Error: ${error.message || error}`);
      setTranscription('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    } finally {
      setIsProcessing(false);
      setRecordedAudioPath(null);
    }
  }

  async function playRecordedAudio() {
    if (!recordedAudioPath) return;
    try {
      setTranscription('ğŸ”Š éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‹ã‚‰ãƒ†ã‚¹ãƒˆå†ç”Ÿã—ã¦ã„ã¾ã™...');
      const { sound } = await Audio.Sound.createAsync({ uri: recordedAudioPath });
      await sound.playAsync();
    } catch (error) {
      console.error('å†ç”Ÿã‚¨ãƒ©ãƒ¼', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    }
  }

  return {
    isRecording, transcription, isProcessing, recordedAudioPath, downloadProgress,
    processLogs, // ã€è¿½åŠ ã€‘UIå´ã«ãƒ­ã‚°ã‚’æ¸¡ã™
    startRecording, stopRecording, saveAndTranscribe, cancelDownload, playRecordedAudio,
    isModelLoaded: !!whisperContext,
  };
}