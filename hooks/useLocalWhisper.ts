import { useState, useEffect, useRef } from 'react';
import { Alert } from 'react-native';
import { Audio } from 'expo-av'; // æ¨©é™ã¨ãƒ†ã‚¹ãƒˆå†ç”Ÿç”¨ã¨ã—ã¦ã®ã¿æ®‹ã—ã¾ã™
import AudioRecord from 'react-native-audio-record'; // æœ€é«˜ã®WAVç”Ÿæˆãƒ„ãƒ¼ãƒ«ã«å¸°é‚„ã—ã¾ã™
import { initWhisper, WhisperContext } from 'whisper.rn';
import RNFS from 'react-native-fs';

export function useLocalWhisper() {
  const [whisperContext, setWhisperContext] = useState<WhisperContext | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [recordedAudioPath, setRecordedAudioPath] = useState<string | null>(null);
  const [downloadProgress, setDownloadProgress] = useState<number>(0);
  const downloadJobId = useRef<number>(-1);

  useEffect(() => {
    async function loadModel() {
      try {
        const documentDirectory = RNFS.DocumentDirectoryPath;
        if (!documentDirectory) throw new Error('ç«¯æœ«ã®ä¿å­˜é ˜åŸŸã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚');

        const finalPath = `${documentDirectory}/ggml-base.bin`;
        const tmpPath = `${documentDirectory}/ggml-base.tmp`;

        if (await RNFS.exists(tmpPath)) await RNFS.unlink(tmpPath);

        let needsDownload = true;
        if (await RNFS.exists(finalPath)) {
          const stat = await RNFS.stat(finalPath);
          if (stat.size / (1024 * 1024) > 100) {
            needsDownload = false;
            setTranscription('AIã®æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã™ã€‚');
          } else {
            await RNFS.unlink(finalPath);
          }
        }

        if (needsDownload) {
          setTranscription('é«˜ç²¾åº¦AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...');
          const modelUrl = 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin';
          
          const ret = RNFS.downloadFile({
            fromUrl: modelUrl,
            toFile: tmpPath,
            progressInterval: 200,
            progress: (res) => {
              setDownloadProgress(Math.round((res.bytesWritten / res.contentLength) * 100));
            }
          });
          downloadJobId.current = ret.jobId;

          const downloadResult = await ret.promise;
          if (downloadResult.statusCode === 200) {
            await RNFS.moveFile(tmpPath, finalPath);
            setDownloadProgress(0);
            setTranscription('é«˜ç²¾åº¦AIã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚');
          } else {
             throw new Error(`HTTP ${downloadResult.statusCode}`);
          }
        }

        const context = await initWhisper({ filePath: finalPath });
        setWhisperContext(context);
      } catch (error) {
        setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šAIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚');
      }
    }
    loadModel();
  }, []);

  function cancelDownload() {
    if (downloadJobId.current !== -1) {
      RNFS.stopDownload(downloadJobId.current);
      setDownloadProgress(0);
      setTranscription('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚');
    }
  }

  // ã€ä¿®æ­£ã€‘WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«ç‰¹åŒ–ã—ãŸ AudioRecord ã‚’å†ã³æ¡ç”¨
  async function startRecording() {
    try {
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        Alert.alert('æ¨©é™ã‚¨ãƒ©ãƒ¼', 'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
        return;
      }
      
      AudioRecord.init({ 
        sampleRate: 16000, // AIå¿…é ˆã®16kHz
        channels: 1,       // AIå¿…é ˆã®ãƒ¢ãƒãƒ©ãƒ«
        bitsPerSample: 16, // AIå¿…é ˆã®16ãƒ“ãƒƒãƒˆ
        audioSource: 1,    // æ¨™æº–ãƒã‚¤ã‚¯ï¼ˆç„¡éŸ³åŒ–å›é¿ï¼‰
        wavFile: 'whisper_audio.wav' 
      });
      
      AudioRecord.start();
      setIsRecording(true);
      setRecordedAudioPath(null);
      setTranscription('éŒ²éŸ³ä¸­...');
    } catch (error) {
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚');
    }
  }

  async function stopRecording() {
    if (!isRecording) return;
    try {
      const path = await AudioRecord.stop();
      setIsRecording(false);

      // ã€æœ€é‡è¦ã€‘Android/iOSå•ã‚ãšã€C++ã‚¨ãƒ³ã‚¸ãƒ³ã«çµ¶å¯¾ãƒ‘ã‚¹ã‚’ä¼ãˆã‚‹ãŸã‚ã® file:// ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å¼·åˆ¶ä»˜ä¸
      const finalPath = path.startsWith('file://') ? path : `file://${path}`;
      
      setRecordedAudioPath(finalPath);
      setTranscription('éŒ²éŸ³ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã€Œä¿å­˜ã—ã¦æ–‡å­—èµ·ã“ã—ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚');
    } catch (error) {
      console.error('éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼', error);
    }
  }

  async function saveAndTranscribe() {
    if (!recordedAudioPath || !whisperContext || isProcessing) return;
    setIsProcessing(true);
    setTranscription('WAVéŸ³å£°ã‚’AIã‚¨ãƒ³ã‚¸ãƒ³ã«é€ä¿¡ã—ã€æ¨è«–ã—ã¦ã„ã¾ã™...\nï¼ˆæ•°åç§’ã‹ã‹ã‚Šã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚’é–‰ã˜ãªã„ã§ãã ã•ã„ï¼‰');
    
    try {
      // ç´”ç²‹ãªWAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã€è¨€èªæŒ‡å®šã®ã¿ã§å‹è² ã™ã‚‹
      const { result } = await whisperContext.transcribe(recordedAudioPath, { language: 'ja' });
      setTranscription(result || "ï¼ˆæ¨è«–å®Œäº†ã—ã¾ã—ãŸãŒã€AIãŒè¨€è‘‰ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰");
    } catch (error) {
      console.error('æ¨è«–å¤±æ•—', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    } finally {
      setIsProcessing(false);
      setRecordedAudioPath(null);
    }
  }

  async function playRecordedAudio() {
    if (!recordedAudioPath) return;
    try {
      setTranscription('ğŸ”Š éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‹ã‚‰ãƒ†ã‚¹ãƒˆå†ç”Ÿã—ã¦ã„ã¾ã™...');
      const { sound } = await Audio.Sound.createAsync({ uri: recordedAudioPath });
      await sound.playAsync();
    } catch (error) {
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    }
  }

  return {
    isRecording, transcription, isProcessing, recordedAudioPath, downloadProgress,
    startRecording, stopRecording, saveAndTranscribe, cancelDownload, playRecordedAudio,
    isModelLoaded: !!whisperContext,
  };
}