import { Audio } from 'expo-av';
import { useEffect, useRef, useState } from 'react';
import { Alert } from 'react-native';
import AudioRecord from 'react-native-audio-record';
import RNFS from 'react-native-fs';
import { initWhisper, WhisperContext } from 'whisper.rn';

export function useLocalWhisper() {
  const [whisperContext, setWhisperContext] = useState<WhisperContext | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [recordedAudioPath, setRecordedAudioPath] = useState<string | null>(null);
  const [downloadProgress, setDownloadProgress] = useState<number>(0);
  const downloadJobId = useRef<number>(-1);

  useEffect(() => {
    async function loadModel() {
      try {
        const documentDirectory = RNFS.DocumentDirectoryPath;
        if (!documentDirectory) throw new Error('ç«¯æœ«ã®ä¿å­˜é ˜åŸŸã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚');

        const finalPath = `${documentDirectory}/ggml-base.bin`;
        const tmpPath = `${documentDirectory}/ggml-base.tmp`;

        if (await RNFS.exists(tmpPath)) await RNFS.unlink(tmpPath);

        let needsDownload = true;
        if (await RNFS.exists(finalPath)) {
          const stat = await RNFS.stat(finalPath);
          if (stat.size / (1024 * 1024) > 100) {
            needsDownload = false;
            setTranscription('AIã®æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã™ã€‚');
          } else {
            await RNFS.unlink(finalPath);
          }
        }

        if (needsDownload) {
          setTranscription('é«˜ç²¾åº¦AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...');
          const modelUrl = 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin';
          
          const ret = RNFS.downloadFile({
            fromUrl: modelUrl,
            toFile: tmpPath,
            progressInterval: 200,
            progress: (res) => {
              setDownloadProgress(Math.round((res.bytesWritten / res.contentLength) * 100));
            }
          });
          downloadJobId.current = ret.jobId;

          const downloadResult = await ret.promise;
          if (downloadResult.statusCode === 200) {
            await RNFS.moveFile(tmpPath, finalPath);
            setDownloadProgress(0);
            setTranscription('é«˜ç²¾åº¦AIã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚');
          } else {
             throw new Error(`HTTP ${downloadResult.statusCode}`);
          }
        }

        const context = await initWhisper({ filePath: finalPath });
        setWhisperContext(context);
      } catch (error: any) {
        // ã€ä¿®æ­£ã€‘ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’æ¡ã‚Šã¤ã¶ã•ãšã€å¿…ãšã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ã™ã‚‹
        console.error('ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—', error);
        setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šAIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚');
      }
    }
    loadModel();
  }, []);

  function cancelDownload() {
    if (downloadJobId.current !== -1) {
      RNFS.stopDownload(downloadJobId.current);
      setDownloadProgress(0);
      setTranscription('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚');
    }
  }

  async function startRecording() {
    try {
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        Alert.alert('æ¨©é™ã‚¨ãƒ©ãƒ¼', 'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
        return;
      }
      
      AudioRecord.init({ 
        sampleRate: 16000,
        channels: 1,      
        bitsPerSample: 16,
        audioSource: 1,   
        wavFile: 'whisper_audio.wav' 
      });
      
      AudioRecord.start();
      setIsRecording(true);
      setRecordedAudioPath(null);
      setTranscription('éŒ²éŸ³ä¸­...');
    } catch (error) {
      // ã€ä¿®æ­£ã€‘ã“ã“ã§ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å‡ºåŠ›
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚');
    }
  }

  async function stopRecording() {
    if (!isRecording) return;
    try {
      const path = await AudioRecord.stop();
      setIsRecording(false);

      const finalPath = path.startsWith('file://') ? path : `file://${path}`;
      
      setRecordedAudioPath(finalPath);
      setTranscription('éŒ²éŸ³ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã€Œä¿å­˜ã—ã¦æ–‡å­—èµ·ã“ã—ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚');
    } catch (error) {
      console.error('éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼', error);
    }
  }

  async function saveAndTranscribe() {
    if (!recordedAudioPath || !whisperContext || isProcessing) return;
    setIsProcessing(true);
    setTranscription('WAVéŸ³å£°ã‚’AIã‚¨ãƒ³ã‚¸ãƒ³ã«é€ä¿¡ã—ã€æ¨è«–ã—ã¦ã„ã¾ã™...\nï¼ˆæ•°åç§’ã‹ã‹ã‚Šã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚’é–‰ã˜ãªã„ã§ãã ã•ã„ï¼‰');
    
    try {
      // ã€ãƒ‡ãƒãƒƒã‚°è¿½åŠ ã€‘AIã«æ¸¡ã™ç›´å‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãªæƒ…å ±ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
      const stat = await RNFS.stat(recordedAudioPath);
      console.log(`[ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–] å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: ${recordedAudioPath}`);
      console.log(`[ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–] ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ${stat.size} bytes`);

      const { result } = await whisperContext.transcribe(recordedAudioPath, { 
        language: 'ja',
        // ã€æ–°è¦ã€‘C++ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨ˆç®—é€²æ—ã‚’JSå´ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å—ã‘å–ã‚‹
        onProgress: (progress: number) => {
          console.log(`[AIã‚¨ãƒ³ã‚¸ãƒ³å†…éƒ¨] æ¨è«–é€²æ—: ${progress}%`);
          // ç”»é¢ã«ã‚‚é€²æ—ã‚’è¡¨ç¤ºã•ã›ã‚‹
          setTranscription(`AIãŒæ¨è«–ä¸­... è„³å†…å‡¦ç†: ${progress}%\nï¼ˆã‚¢ãƒ—ãƒªã‚’é–‰ã˜ãªã„ã§ãã ã•ã„ï¼‰`);
        }
      });
      
      console.log(`[AIã‚¨ãƒ³ã‚¸ãƒ³å†…éƒ¨] æœ€çµ‚å‡ºåŠ›: ${result}`);
      setTranscription(result || "ï¼ˆæ¨è«–å®Œäº†ã—ã¾ã—ãŸãŒã€AIãŒè¨€è‘‰ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰");
      
    } catch (error) {
      console.error('æ¨è«–å¤±æ•—', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    } finally {
      setIsProcessing(false);
      setRecordedAudioPath(null);
    }
  }

  async function playRecordedAudio() {
    if (!recordedAudioPath) return;
    try {
      setTranscription('ğŸ”Š éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‹ã‚‰ãƒ†ã‚¹ãƒˆå†ç”Ÿã—ã¦ã„ã¾ã™...');
      const { sound } = await Audio.Sound.createAsync({ uri: recordedAudioPath });
      await sound.playAsync();
    } catch (error) {
      // ã€ä¿®æ­£ã€‘ã“ã“ã§ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å‡ºåŠ›
      console.error('å†ç”Ÿã‚¨ãƒ©ãƒ¼', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    }
  }

  return {
    isRecording, transcription, isProcessing, recordedAudioPath, downloadProgress,
    startRecording, stopRecording, saveAndTranscribe, cancelDownload, playRecordedAudio,
    isModelLoaded: !!whisperContext,
  };
}