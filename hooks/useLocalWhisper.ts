import { useState, useEffect, useRef } from 'react';
import { Alert, Platform } from 'react-native';
import { Audio } from 'expo-av';
import { initWhisper, WhisperContext } from 'whisper.rn';
import RNFS from 'react-native-fs';

export function useLocalWhisper() {
  const [whisperContext, setWhisperContext] = useState<WhisperContext | null>(null);
  
  // ã€æ–°è¦ã€‘expo-avã®éŒ²éŸ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¿æŒã™ã‚‹ã‚¹ãƒ†ãƒ¼ãƒˆ
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [recordedAudioPath, setRecordedAudioPath] = useState<string | null>(null);
  
  const [downloadProgress, setDownloadProgress] = useState<number>(0);
  const downloadJobId = useRef<number>(-1);

  useEffect(() => {
    async function loadModel() {
      try {
        const documentDirectory = RNFS.DocumentDirectoryPath;
        if (!documentDirectory) throw new Error('ç«¯æœ«ã®ä¿å­˜é ˜åŸŸã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚');

        const finalPath = `${documentDirectory}/ggml-base.bin`;
        const tmpPath = `${documentDirectory}/ggml-base.tmp`;

        if (await RNFS.exists(tmpPath)) {
          await RNFS.unlink(tmpPath);
        }

        let needsDownload = true;
        if (await RNFS.exists(finalPath)) {
          const stat = await RNFS.stat(finalPath);
          if (stat.size / (1024 * 1024) > 100) {
            needsDownload = false;
            setTranscription('AIã®æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã™ã€‚');
          } else {
            await RNFS.unlink(finalPath);
          }
        }

        if (needsDownload) {
          setTranscription('é«˜ç²¾åº¦AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...');
          const modelUrl = 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin';
          
          const ret = RNFS.downloadFile({
            fromUrl: modelUrl,
            toFile: tmpPath,
            progressInterval: 200,
            progress: (res) => {
              const percentage = (res.bytesWritten / res.contentLength) * 100;
              setDownloadProgress(Math.round(percentage));
            }
          });
          
          downloadJobId.current = ret.jobId;

          const downloadResult = await ret.promise;
          
          if (downloadResult.statusCode === 200) {
            await RNFS.moveFile(tmpPath, finalPath);
            setDownloadProgress(0);
            setTranscription('é«˜ç²¾åº¦AIã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚');
          } else {
             throw new Error(`ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€šä¿¡å¤±æ•—: HTTP ${downloadResult.statusCode}`);
          }
        }

        const context = await initWhisper({ filePath: finalPath });
        setWhisperContext(context);

      } catch (error: any) {
        if (error.message === 'Download has been aborted') {
          console.log('ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ');
        } else {
          console.error('ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—', error);
          setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šAIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚');
        }
      }
    }
    loadModel();
  }, []);

  function cancelDownload() {
    if (downloadJobId.current !== -1) {
      RNFS.stopDownload(downloadJobId.current);
      setDownloadProgress(0);
      setTranscription('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã™ã‚‹ã¨æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã›ã¾ã™ã€‚');
    }
  }

  // ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ·æ–°ã€‘expo-avã«ã‚ˆã‚‹å …ç‰¢ãªéŒ²éŸ³ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆWhisperå°‚ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
  async function startRecording() {
    try {
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        Alert.alert('æ¨©é™ã‚¨ãƒ©ãƒ¼', 'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
        return;
      }
      
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      // ã€ä¿®æ­£ã€‘é«˜éŸ³è³ªãƒ—ãƒªã‚»ãƒƒãƒˆã‚’æ¨ã¦ã€WhisperãŒè¦æ±‚ã™ã‚‹å³æ ¼ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚«ã‚¹ã‚¿ãƒ æŒ‡å®š
      const whisperOptions = {
        android: {
          extension: '.m4a',
          outputFormat: Audio.AndroidOutputFormat.MPEG_4,
          audioEncoder: Audio.AndroidAudioEncoder.AAC,
          sampleRate: 16000, // ã€æœ€é‡è¦ã€‘AIã®è€³ã¨åŒã˜å‘¨æ³¢æ•°ï¼ˆ16kHzï¼‰ã«å›ºå®š
          numberOfChannels: 1, // ã‚¹ãƒ†ãƒ¬ã‚ª(2)ã§ã¯ãªããƒ¢ãƒãƒ©ãƒ«(1)ã«å›ºå®š
          bitRate: 64000,
        },
        ios: {
          extension: '.wav',
          audioQuality: Audio.IOSAudioQuality.HIGH,
          sampleRate: 16000,
          numberOfChannels: 1,
          bitRate: 256000,
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
        web: {
          mimeType: 'audio/webm',
          bitsPerSecond: 128000,
        },
      };

      // ã‚«ã‚¹ã‚¿ãƒ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ã£ã¦ã€æœ€åˆã‹ã‚‰AIãŒèª­ã‚ã‚‹å½¢ã§éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹
      const { recording: newRecording } = await Audio.Recording.createAsync(whisperOptions);
      
      setRecording(newRecording);
      setIsRecording(true);
      setRecordedAudioPath(null);
      setTranscription('éŒ²éŸ³ä¸­...');
    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚');
    }
  }

  async function stopRecording() {
    if (!recording) return;
    try {
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      if (!uri) throw new Error('éŸ³å£°URIãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ');

      // C++ã‚¨ãƒ³ã‚¸ãƒ³ãŒèª­ã¿è¾¼ã‚ã‚‹ã‚ˆã†ã€Androidã®å ´åˆã¯ file:// ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å®‰å…¨ã«é™¤å»
      let path = uri;
      if (Platform.OS === 'android' && path.startsWith('file://')) {
        path = path.replace('file://', '');
      }

      setRecording(null);
      setIsRecording(false);
      setRecordedAudioPath(path);
      setTranscription('éŒ²éŸ³ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã€Œä¿å­˜ã—ã¦æ–‡å­—èµ·ã“ã—ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚');
    } catch (error) {
      console.error('éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼', error);
    }
  }

  async function saveAndTranscribe() {
    if (!recordedAudioPath || !whisperContext || isProcessing) return;
    setIsProcessing(true);
    setTranscription('éŸ³å£°ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã€é«˜ç²¾åº¦AIãŒæ¨è«–ã—ã¦ã„ã¾ã™...\nï¼ˆæ•°åç§’ã‹ã‹ã‚Šã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚’é–‰ã˜ãªã„ã§ãã ã•ã„ï¼‰');
    
    try {
      // OSæ¨™æº–ã®ãƒ‡ã‚³ãƒ¼ãƒ€ãŒè‡ªå‹•è§£å‡ã™ã‚‹ãŸã‚ã€ç ´æã®å¿ƒé…ãªã—ã«ç›´æ¥æ¨è«–ã‚’å®Ÿè¡Œã§ãã‚‹
      const { result } = await whisperContext.transcribe(recordedAudioPath, { language: 'ja' });
      setTranscription(result || "ï¼ˆæ¨è«–å®Œäº†ã—ã¾ã—ãŸãŒã€AIãŒè¨€è‘‰ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰");
    } catch (error) {
      console.error('æ¨è«–å¤±æ•—', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    } finally {
      setIsProcessing(false);
      setRecordedAudioPath(null);
    }
  }

  async function playRecordedAudio() {
    if (!recordedAudioPath) return;
    try {
      setTranscription('ğŸ”Š éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‹ã‚‰ãƒ†ã‚¹ãƒˆå†ç”Ÿã—ã¦ã„ã¾ã™...');
      const uri = recordedAudioPath.startsWith('file://') ? recordedAudioPath : `file://${recordedAudioPath}`;
      const { sound } = await Audio.Sound.createAsync({ uri });
      await sound.playAsync();
    } catch (error) {
      console.error('å†ç”Ÿã‚¨ãƒ©ãƒ¼', error);
      setTranscription('ã‚¨ãƒ©ãƒ¼ï¼šéŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    }
  }

  return {
    isRecording,
    transcription,
    isProcessing,
    recordedAudioPath,
    downloadProgress,
    startRecording,
    stopRecording,
    saveAndTranscribe,
    cancelDownload,
    playRecordedAudio,
    isModelLoaded: !!whisperContext,
  };
}